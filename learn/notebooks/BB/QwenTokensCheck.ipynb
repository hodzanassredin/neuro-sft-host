{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd840afe-eacd-4f4e-83d1-508f14d42cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "assert torch.cuda.is_available(), \"you need cuda for this part\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492985b3-4f34-47ed-93ce-793f7e7361c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели и токенизатора\n",
    "model_name = \"Qwen/Qwen2.5-Coder-3B\"  # Убедитесь, что это правильное имя модели\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=device,quantization_config=bnb_config,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30f735c7-8560-46a9-aa33-f68ecd53affc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерированный текст:\n",
      "In Python, the print() function is used to display data. To output “hello world” using the print() function, you can type the following code in a Python file:\n",
      "\n",
      "print(\"hello world\")\n",
      "This will output the text “hello world” to the console. NOTE: Make sure that the file extension for this Python file is .py for it to be runnable and compiled. You can also run this code as a script by writing the code in a Python file and then running the command python filename.py, if the file is named something other than main.\n",
      "\n",
      "Additionally, you can create a Python virtual environment to ensure that this program runs on a consistent environment, even with different versions of Python installed. To create a virtual environment, run the command `python -m venv venv`, where `venv` is the name of your virtual environment. To activate the virtual environment, run the command `. venv/bin/activate` (on Unix or macOS) or `. venv\\Scripts\\activate` (on Windows).\n",
      "\n",
      "To exit the virtual environment, run the command `deactivate`. You can also deactivate the virtual environment by pressing `Ctrl + c`. As well, you can deactivate the virtual environment permanently by deleting the directory named `venv`.<|endoftext|>\n",
      "\n",
      "Специальные токены в тексте:\n",
      "<|endoftext|>: 1 раз(а)\n",
      "<|im_start|>: 3 раз(а)\n",
      "<|im_end|>: 2 раз(а)\n"
     ]
    }
   ],
   "source": [
    "def prompt_to_chat(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    return text\n",
    "\n",
    "# Входной текст для генерации\n",
    "input_text = \"Сгенерируй программу выводящую hello world на python.\"\n",
    "input_text = prompt_to_chat(input_text)\n",
    "# Токенизация входного текста\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Генерация текста\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,  # Максимальная длина генерируемого текста\n",
    "    num_return_sequences=1,  # Количество генерируемых последовательностей\n",
    "    do_sample=True,  # Использовать сэмплирование\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "# Декодирование сгенерированного текста\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "\n",
    "# Вывод сгенерированного текста\n",
    "print(\"Сгенерированный текст:\")\n",
    "print(generated_text[len(input_text):])\n",
    "\n",
    "# Просмотр специальных токенов в сгенерированном тексте\n",
    "special_tokens = tokenizer.all_special_tokens\n",
    "special_tokens_in_text = [token for token in special_tokens if token in generated_text]\n",
    "\n",
    "print(\"\\nСпециальные токены в тексте:\")\n",
    "for token in special_tokens_in_text:\n",
    "    print(f\"{token}: {generated_text.count(token)} раз(а)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d03538e0-d480-4610-a3b1-5833cfdbfbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерированный текст:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Сгенерируй программу выводящую hello world на python.\n",
      "assistant\n",
      "Of course! Here's a simple Python program that prints \"Hello, world!\" to the console:\n",
      "```\n",
      "print(\"Hello, world!\")\n",
      "``<|file_sep|><|fim_prefix|>/12.22.2022/04/04.py\n",
      "<|fim_suffix|>nt\n",
      "<|fim_middle|>#!/usr/bin/env python\n",
      "from subprocess import call\n",
      "print ('hello')\n",
      "call([\"/home/petkav/petka/instsall/Install.sh\", \"--yes\"])\n",
      "pri<|file_sep|>/10.13.\n"
     ]
    }
   ],
   "source": [
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Вывод сгенерированного текста\n",
    "print(\"Сгенерированный текст:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e6083-fc85-4077-a863-fdf9d389b9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
