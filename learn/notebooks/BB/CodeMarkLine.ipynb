{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b04724f-bb7e-4933-a548-5f7324c99033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25done\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.12/site-packages (from seqeval) (1.26.4)\n",
      "Collecting scikit-learn>=0.21.3 (from seqeval)\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Downloading scipy-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=6d28a1cef3d506e698f19a6e9922103fe74a9d786bcf741d357c7a3dd30a1fbd\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
      "Successfully built seqeval\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, seqeval\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.1 seqeval-1.2.2 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fef4d7-d701-4a1c-83f6-b61891d280cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97412ea9-fd55-4656-a08d-77a3f5356fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "import peft\n",
    "import datasets\n",
    "import evaluate\n",
    "import time\n",
    "import re\n",
    "assert torch.cuda.is_available(), \"you need cuda for this part\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22c2d44e-4d35-4dc1-9d1b-4f24f54b9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b13b83d-9f18-4878-af4b-0306a137f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"C\",\"T\"]\n",
    "id2label = {\n",
    "    0: \"C\",\n",
    "    1: \"T\",\n",
    "}\n",
    "\n",
    "label2id = {\n",
    "    \"C\": 0,\n",
    "    \"T\": 1,\n",
    "}\n",
    "pattern = r'END\\s+[A-Za-z0-9\\_]+\\.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6506d47b-df74-41f1-88ce-6c2ac1e6f2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Это пример текста.\n",
      "(* Это однострочный комментарий *)\n",
      "Это продолжение текста.\n",
      "\n",
      "Это еще текст.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_multiline_comments(text):\n",
    "    # Регулярное выражение для поиска многострочных комментариев\n",
    "    pattern = r'\\(\\*[^)]*?\\n.*?\\*\\)'\n",
    "\n",
    "    # Используем re.sub для замены всех найденных многострочных комментариев на пустую строку\n",
    "    result = re.sub(pattern, '', text, flags=re.DOTALL)\n",
    "\n",
    "    return result\n",
    "\n",
    "# Пример использования\n",
    "text = \"\"\"\n",
    "Это пример текста.\n",
    "(* Это однострочный комментарий *)\n",
    "Это продолжение текста.\n",
    "(*\n",
    "Это многострочный комментарий\n",
    "на несколько строк\n",
    "*)\n",
    "Это еще текст.\n",
    "\"\"\"\n",
    "\n",
    "cleaned_text = remove_multiline_comments(text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6db3fc9-26aa-486d-8fe7-a1972e202349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "code_dataset = datasets.load_dataset(\"hodza/BlackBox.Shkola.2014\")['train']\n",
    "#code_dataset = code_dataset.filter(lambda example: '/Mod/' in example[\"names\"])\n",
    "\n",
    "CODE_WORDS = [\n",
    "    'ABSTRACT','EXTENSIBLE','POINTER',\n",
    "\t'ARRAY','FOR','PROCEDURE',\n",
    "\t'BEGIN','IF','RECORD',\n",
    "\t'BY','IMPORT','REPEAT',\n",
    "\t'CASE','IN','RETURN',\n",
    "\t'CLOSE','IS','THEN',\n",
    "\t'CONST','LIMITED','TO',\n",
    "\t'DIV','LOOP','TYPE',\n",
    "\t'DO','MOD','UNTIL',\n",
    "\t'ELSE','MODULE','VAR',\n",
    "\t'ELSIF','NIL','WHILE',\n",
    "\t'EMPTY','OF','WITH',\n",
    "\t'END','OR',\n",
    "\t'EXIT','OUT']\n",
    "\n",
    "def is_contains_code(line):\n",
    "    return any(line.find(s) != -1 for s in CODE_WORDS)\n",
    "\n",
    "def strip_after_end(sample):\n",
    "    text = re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f-\\xff]', '', sample['texts'])\n",
    "    text = remove_multiline_comments(text)\n",
    "    lines = text.split('\\n')\n",
    "    if 'Docu/' in sample['names']:\n",
    "        code = [l for l in lines if is_contains_code(l)]\n",
    "        text = [l for l in lines if not is_contains_code(l)]\n",
    "    elif 'Rsrc/' in sample['names']:\n",
    "        code = []\n",
    "        text = []\n",
    "    else:\n",
    "        code = []\n",
    "        text = []\n",
    "        is_code = True\n",
    "        for l in lines:\n",
    "            if is_code:\n",
    "                code.append(l)\n",
    "            else:\n",
    "                if is_contains_code(l):\n",
    "                    code.append(l)\n",
    "                else:\n",
    "                    text.append(l)\n",
    "            match = re.search(pattern, l)\n",
    "            if match:\n",
    "                if not is_code:\n",
    "                    code += text\n",
    "                    text = []\n",
    "                is_code = False\n",
    "    return { \"code_lines\" : code,  \"text_lines\" : text, 'names' : sample['names']}\n",
    "        \n",
    "code_dataset = code_dataset.map(strip_after_end)\n",
    "code_lines = [l for x in code_dataset for l in x['code_lines'] if not l.isspace() and len(l) > 0]\n",
    "text_lines = [l for x in code_dataset for l in x['text_lines'] if not l.isspace() and len(l) > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfdcbc22-5437-48e8-a2af-abfe3aa5da9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27422, 150620)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_lines), len(code_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2015fe57-3c35-4b8f-9613-66a643ae962d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['After compiling the module, a dialog box can be created for the items exported by ObxAddress1 using command NewForm... from menu Controls. Just enter the name ObxAddress1 into the Link field, and then click on the Create button. The type information extracted by the compiler is available to the BlackBox Component Builder at run-time, and is used to automatically create a data-entry form for the record declaration above. The form has a simple default layout. This default layout may be edited, and then opened as a dialog using the Open as Aux Dialog command in menu Controls.',\n",
       " 'The text entry fields and the checkbox of the form are directly linked to the fields name, city, country, customer  and update of the record ObxAddress1.adr. The button is linked to the command OpenText, i.e., to the procedure exported by module ObxAddress1. Clicking the button causes procedure OpenText to be called. As a result, a new text is created; a textual report based on the variable adr is written to this text; a new text view is created; and the view is opened in a window, displaying the report.',\n",
       " 'Text entry fields, checkboxes, and other so-called controls may have properties that could be inspected and modified by a suitable control property inspector. Instead of first writing a module and then creating an initial layout, as we have done above, the form can be constructed first, and the corresponding module written later. A BlackBox Component Builder dialog does not necessarily correspond to exactly one record variable. The individual controls of a dialog box may be linked to records in different modules, and a dialog box may also contain other views which are not controls, such as pictures.',\n",
       " \"A form can be saved from within the visual editor; thereafter it can be attached to a menu entry, or another dialog's button. Dialog boxes are saved in the standard document format, in a platformђindependent way. This approach eliminates the need for an intermediate source code generator and allows to later modify the dialog boxes without having to recompile anything.\",\n",
       " 'And more ...',\n",
       " 'After this first impression, you may want to consult your documentation for an in-depth coverage of the BlackBox Component Builder. Select the Contents item in the Help menu for an overview over the documentation. From there, the complete on-line documentation can be reached via hyperlinks.',\n",
       " 'How should you start to get acquainted with BlackBox? We suggest that you start with the introduction texts ABriefHistoryofPascal and Roadmap.',\n",
       " 'The documentation consists of four major parts:',\n",
       " ' A usermanual that describes the user interface and most important commands of the BlackBox Component Builder',\n",
       " ' A tutorial that first introduces the general BlackBox design patterns (chapters 1 to 3). Graphical user interfaces, forms, and controls are discussed in chapter4. The text subsystem is explained in chapter5. The remaining chapter6 deals with view programming.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c42c8005-0575-4729-a980-68b4111403bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 178042\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = datasets.Dataset.from_dict({'text' : code_lines, 'label' : [0] * len(code_lines)})\n",
    "t = datasets.Dataset.from_dict({'text' : text_lines, 'label' : [1] * len(text_lines)})\n",
    "\n",
    "dataset = datasets.concatenate_datasets([c,t])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb29c53f-01a2-451e-81f2-780008a6750d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '\\t\\t\\tCheckSym(rbrak);', 'label': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[18419]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3393c9d1-7869-453a-9342-2e6f3848d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29d7ac26-63df-48ae-8627-cf405f0e8354",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert/distilbert-base-cased\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "650ecf3d-eebc-4282-aa5e-78e60d581b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name, device_map=device, num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44874f37-4364-446e-906d-ef1aacfa418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8805484b-abf2-4e44-9b11-8d9c4a6a21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "183e544f-1793-4f6e-b448-d95f65e6c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#labels = [label_list[i] for i in dataset[f\"tags\"]]\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a24392a6-aadd-4e61-9bc7-330760c7d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "119efc43-738a-43cc-b3c2-33ba405b0aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 133531/133531 [00:02<00:00, 44789.29 examples/s]\n",
      "Map: 100%|██████████| 44511/44511 [00:01<00:00, 43629.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c1fd336-0ae0-4612-92dd-58fb87e74f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='288' max='4172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 288/4172 01:39 < 22:25, 2.89 it/s, Epoch 0.14/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 27\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results/code_model_line\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m  \n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m trainer \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     18\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/trainer.py:2536\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2537\u001b[0m ):\n\u001b[1;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"./results/code_model_line\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    gradient_accumulation_steps = 2,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    " \n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    \n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df366fff-0f9f-4fef-a403-cd830353a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = transformers.pipeline('text-classification', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb06d9-21eb-44b2-b6b9-f99daf37f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = datasets.load_dataset(\"hodza/BlackBox.Shkola.2014\")['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c25b5c-8198-40a9-b66b-63d7888a956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_dataset[1]['texts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c087dc2e-49af-422b-914a-331b4d22ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C \n",
      "C Проект ИНФОРМАТИКА-21\n",
      "C \n",
      "T Внедрение современных технологий и методов программирования \n",
      "T в общие базовые курсы программирования \n",
      "T (5-11 классы средних школ и 1-3 курсы университетов, \n",
      "T независимо от профиля и специализации)\n",
      "C с целью создания единого пространства \n",
      "C для преподавания основ ИТ \n",
      "T как естественного продолжения \n",
      "T единой общей системы преподавания основ математики\n",
      "C \n",
      "C Подробная информация о проекте: http://www.inr.ac.ru/~info21/\n",
      "C \n",
      "C Для вопросов и замечаний: info21@inr.ac.ru\n",
      "C \n",
      "T Благодарности. Российские версии среды обучения и разработки программ, носящие название Блэкбокс, основаны на системе программирования BlackBox Component Builder, созданной в Oberon microsystems, Inc., в развитие идей, впервые реализованных в Системе Оберон Никлауса Вирта и Юрга Гуткнехта (Niklaus Wirth, Jurg Gutknecht, ETH, Zurich, Switzerland). Со-архитектор Блэкбокса Клеменс Шиперски (Clemens Szyperski) работает в исследовательском подразделении корпорации Майкрософт (Microsoft Research).\n",
      "C \n",
      "C Вклад в создание данного пакета внесли множество людей, в том числе: Wolfgang Weck, И.Н.Горячев, И.А.Дехтяренко, И.Е.Ермаков, А.С.Ильин, ketmar, Ю.Л.Костюк, Л.Г.Куркина, Т.В.Овсянникова, А.И.Попков, Б.В.Рюмшин, Е.Э.Темиргалеев, Ф.В.Ткачев, И.А.Цвелая.\n",
      "C Особая благодарность  компании Метасистемы (г.Орел), а также всем тем, кто принял участие в переводах документации на русский язык.\n",
      "C \n",
      "C г Все тексты программ и др. материалы проекта, если не указано иное: проект Информатика-21 ( http://www.inr.ac.ru/~info21/), 2002-2012 гг. Никакое коммерческое использование материалов, в том числе в рамках PR-деятельности коммерческих фирм и т.п., без письменного разрешения авторов не допускается.\n"
     ]
    }
   ],
   "source": [
    "test = re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f-\\xff]', '', val_dataset[1]['texts'])\n",
    "lines = test.split('\\n')\n",
    "res = classifier(lines)\n",
    "for i in range(len(lines)):\n",
    "    print(res[i]['label'], lines[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56272b39-d029-4f66-9113-725d20ac6870",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclassifier\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mс целью создания единого пространства\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "classifier('с целью создания единого пространства')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c07496-a0c2-48f4-adf3-e4345e7c31e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
