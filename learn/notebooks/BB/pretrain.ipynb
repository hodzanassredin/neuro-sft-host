{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c552ef18-d476-4ac1-a932-fe39ae52e36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 21 11:06:50 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.02              Driver Version: 566.03         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "| 47%   59C    P2            123W /  165W |   14025MiB /  16380MiB |     94%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e04ccb-e0e0-4c48-a9c8-efb88642a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "import peft\n",
    "from datasets import load_dataset, Dataset\n",
    "assert torch.cuda.is_available(), \"you need cuda for this part\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "055ff20d-43e1-4f7d-8722-441da81abb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/app/datasets/oberon/docs/bb_ru\"\n",
    "#model_name = \"Qwen/Qwen2.5-Coder-7B\"\n",
    "model_name = 'MTSAIR/Cotype-Nano'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10faa754-675f-49fa-af89-9e2376c3b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_model_path = f\"/app/models/bb_ru_cotype\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ee4c9c-0b68-4bd9-ad3a-b59b9bfad4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "peft_config = peft.LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        \"mlp.down_proj\",\n",
    "        \"self_attn.k_proj\",\n",
    "        \"self_attn.o_proj\",\n",
    "        \"mlp.up_proj\",\n",
    "        \"self_attn.v_proj\",\n",
    "        \"mlp.gate_proj\",\n",
    "        \"self_attn.q_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=peft.TaskType.CAUSAL_LM\n",
    ")\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c948fa-79c1-4c77-a689-78fb5151a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        file_names.append(os.path.join(subdir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8af39ba7-7178-494b-8476-32ececbcf199",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for f in file_names:\n",
    "    with open(f, 'r', encoding='utf-8') as file:\n",
    "        texts.append(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7286ae99-fdaf-4a2f-91dc-05d67cfe7760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 1071\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_dict({'text': texts})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8863282-81bf-4fa5-9226-91d673dcb9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1071 [00:00<?, ? examples/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06627dbd-c8f8-4b09-942d-58439e3cfcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.AutoModelForCausalLM.from_pretrained(model_name, device_map=device,quantization_config=bnb_config,)\n",
    "model._hf_peft_config_loaded = True  # silence a warning from HF trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a2f70-9a12-4316-a57b-7815bb33e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa722e4-6baa-4cdd-913e-23afa5159987",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d30406-4ef7-458d-af63-69a5e6576979",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1c380-ca65-47f0-8ba2-86ca5b777572",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(sft_model_path)\n",
    "tokenizer.save_pretrained(sft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8aa123-881c-4af1-bf8a-f44fd6631057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
