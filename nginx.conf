events {}

http {
    upstream llama_cpp_server {
        server llm-server:8000;  # Порт, на котором работает llama.cpp сервер
    }

    server {
        listen 80;

        location / {
            proxy_pass http://llm-server;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_connect_timeout       300;
            proxy_send_timeout          300;
            proxy_read_timeout          300;
            send_timeout                300;
        }
    }
}