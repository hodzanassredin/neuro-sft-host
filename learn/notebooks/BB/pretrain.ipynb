{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c552ef18-d476-4ac1-a932-fe39ae52e36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 22 19:53:39 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.02              Driver Version: 566.03         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   37C    P8              6W /  165W |    1211MiB /  16380MiB |     16%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A         1      C   /python3.10                                 N/A      |\n",
      "|    0   N/A  N/A         1      C   /python3.10                                 N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e04ccb-e0e0-4c48-a9c8-efb88642a788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "import peft\n",
    "import datasets\n",
    "import time\n",
    "assert torch.cuda.is_available(), \"you need cuda for this part\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6278fc09-ac11-4db4-9b35-f1191285d8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "055ff20d-43e1-4f7d-8722-441da81abb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/app/datasets/oberon/docs/bb_ru\"\n",
    "#model_name = \"Qwen/Qwen2.5-Coder-7B\"\n",
    "model_name = 'MTSAIR/Cotype-Nano'\n",
    "PACKED=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10faa754-675f-49fa-af89-9e2376c3b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_model_name = model_name.split(\"/\")[-1]\n",
    "dataset_name = dataset_path.split(\"/\")[-1]\n",
    "sft_model_path = f\"/app/models/{dataset_name}_{only_model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ee4c9c-0b68-4bd9-ad3a-b59b9bfad4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "peft_config = peft.LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        \"mlp.down_proj\",\n",
    "        \"self_attn.k_proj\",\n",
    "        \"self_attn.o_proj\",\n",
    "        \"mlp.up_proj\",\n",
    "        \"self_attn.v_proj\",\n",
    "        \"mlp.gate_proj\",\n",
    "        \"self_attn.q_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=peft.TaskType.CAUSAL_LM\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61beaedd-5d90-43a1-8b76-ffd9b9a8e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00042bcc-14f2-49c4-af7d-ae4a73113d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_texts():\n",
    "    file_names = [] \n",
    "    for subdir, dirs, files in os.walk(dataset_path):\n",
    "        if not \"/Docu/\" in subdir:\n",
    "            continue\n",
    "        for file in files:\n",
    "            file_names.append(os.path.join(subdir, file))\n",
    "    texts = []\n",
    "    for f in file_names:\n",
    "        with open(f, 'r', encoding='utf-8') as file:\n",
    "            texts.append(file.read())\n",
    "    return texts\n",
    "texts = load_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b02ab931-2403-411e-a760-99f39b7fa17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'overflow_to_sample_mapping', 'labels'],\n",
       "        num_rows: 1962\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'overflow_to_sample_mapping', 'labels'],\n",
       "        num_rows: 491\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 256  # Максимальная длина последовательности\n",
    "stride = 32      # Шаг перекрытия    \n",
    "def tokenize_with_stride(texts):\n",
    "    tokenized_data = tokenizer(\n",
    "        texts,\n",
    "        max_length=block_size,\n",
    "        truncation=True,\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        padding=\"max_length\",  # Дополняем до block_size\n",
    "        return_tensors=\"pt\",   # Возвращаем тензоры PyTorch\n",
    "    )\n",
    "    tokenized_data[\"labels\"] = tokenized_data[\"input_ids\"]\n",
    "    return datasets.Dataset.from_dict(tokenized_data).train_test_split(test_size=0.2)\n",
    "    \n",
    "lm_datasets = tokenize_with_stride(texts)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8863282-81bf-4fa5-9226-91d673dcb9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if False:# probaby need to remove as obsolete\n",
    "    print(\"USING PACKED DATASET\")\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples['text'])\n",
    "    \n",
    "    tokenized_dataset = dataset.map(tokenize_function)\n",
    "    \n",
    "    def group_texts(examples):\n",
    "        # Concatenate all texts.\n",
    "        concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "        total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "        # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "            # customize this part to your needs.\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "        # Split by chunks of max_len.\n",
    "        result = {\n",
    "            k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "            for k, t in concatenated_examples.items()\n",
    "        }\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "        return result\n",
    "    \n",
    "    lm_datasets = tokenized_dataset.map(\n",
    "        group_texts,\n",
    "        batched=True,\n",
    "        batch_size=1000,\n",
    "        num_proc=4,\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c32575a6-319b-4b12-8d09-d6b4f124e3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " и поля ряда (колонок) разделены табуляцией (09X).\n",
      "\n",
      "ReadeTuple читает строку текста базы данных, и присваивает значение строки, занятое одним полем базы данных, каждому соответствующему полю шаблона.\n",
      "\n",
      "AppendInstance прикрепляет копию шаблонного текста в конец выходного файла и затем заменяет все символы-заполнители содержимым соответствующих полей базы данных. Эти подстановки делаются от конца присоедяемого текста к началу, так что из/в-индексы  не становятся недействительными при подстановке. Это и объясняет тот факт, что список полей выстраивается в обратном порядке, последнее поле - первым.   \n",
      "\n",
      "Заметим, что каждая подстановка получает атрибуты текста от первого перемещенного символа, т.е., если символ-заполнитель \"<Name>\" в полужирном шрифте замещается строкой \"Joe\", результирующей заменой будет\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(lm_datasets[\"train\"][99][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06627dbd-c8f8-4b09-942d-58439e3cfcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.AutoModelForCausalLM.from_pretrained(model_name, device_map=device,quantization_config=bnb_config,)\n",
    "model._hf_peft_config_loaded = True  # silence a warning from HF trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e45a2f70-9a12-4316-a57b-7815bb33e07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 18,464,768 || all params: 1,562,179,072 || trainable%: 1.1820\n"
     ]
    }
   ],
   "source": [
    "model = peft.get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93b6e086-af49-4f73-b5dd-c15772e989a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efa722e4-6baa-4cdd-913e-23afa5159987",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "data_collator = transformers.DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=f\"./results/{timestr}/\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    bf16=torch.cuda.get_device_capability(torch.cuda.current_device())[0] >= 8,  \n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=32,\n",
    "    warmup_steps=100, \n",
    "    #eval_steps=32, \n",
    "    #max_steps=512,\n",
    "    \n",
    "    #load_best_model_at_end=True,\n",
    ")\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d30406-4ef7-458d-af63-69a5e6576979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='1220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  62/1220 05:05 < 1:38:12, 0.20 it/s, Epoch 0.99/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>21.156200</td>\n",
       "      <td>2.101048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 22:10:32,414 Resetting dropped connection: huggingface.co\n",
      "2025-01-22 22:10:32,741 https://huggingface.co:443 \"HEAD /MTSAIR/Cotype-Nano/resolve/main/config.json HTTP/11\" 200 0\n",
      "2025-01-22 22:10:32,898 https://huggingface.co:443 \"HEAD /MTSAIR/Cotype-Nano/resolve/main/config.json HTTP/11\" 200 0\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "#trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "44e3bbe0-ea00-44d9-b532-48a5862bf6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='513' max='513' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [513/513 01:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 5.12\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bcf1c380-ca65-47f0-8ba2-86ca5b777572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 19:29:31,304 Resetting dropped connection: huggingface.co\n",
      "2025-01-22 19:29:31,786 https://huggingface.co:443 \"HEAD /MTSAIR/Cotype-Nano/resolve/main/config.json HTTP/11\" 200 0\n",
      "2025-01-22 19:29:31,987 https://huggingface.co:443 \"HEAD /MTSAIR/Cotype-Nano/resolve/main/config.json HTTP/11\" 200 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/app/models/bb_ru_Cotype-Nano/tokenizer_config.json',\n",
       " '/app/models/bb_ru_Cotype-Nano/special_tokens_map.json',\n",
       " '/app/models/bb_ru_Cotype-Nano/vocab.json',\n",
       " '/app/models/bb_ru_Cotype-Nano/merges.txt',\n",
       " '/app/models/bb_ru_Cotype-Nano/added_tokens.json',\n",
       " '/app/models/bb_ru_Cotype-Nano/tokenizer.json')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_path = sft_model_path + f\"_{timestr}\"\n",
    "model.save_pretrained(final_path)\n",
    "tokenizer.save_pretrained(final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8d8aa123-881c-4af1-bf8a-f44fd6631057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 19:57:55,994 https://huggingface.co:443 \"HEAD /MTSAIR/Cotype-Nano/resolve/main/config.json HTTP/11\" 200 0\n",
      "2025-01-22 19:58:20,616 https://huggingface.co:443 \"HEAD /MTSAIR/Cotype-Nano/resolve/main/generation_config.json HTTP/11\" 200 0\n"
     ]
    }
   ],
   "source": [
    "reference_model = transformers.AutoModelForCausalLM.from_pretrained(model_name, device_map=device,quantization_config=bnb_config,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0226c3f9-1c41-4010-b00b-0fa0e125839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "table_template = \"\"\"<table style=\"border:1px solid black\" >\n",
    "  <tr>\n",
    "    <th style=\"text-align: center; border:1px solid black\">PROMPT</th>\n",
    "    <th style=\"text-align: center; border:1px solid black\">BEFORE</th>\n",
    "    <th style=\"text-align: center; border:1px solid black\">AFTER</th>\n",
    "  </tr>\n",
    "{}\n",
    "</table>\"\"\"\n",
    "\n",
    "row_template = '''  <tr>\n",
    "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`{}`</pre></td>\n",
    "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
    "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
    "  </tr>'''\n",
    "\n",
    "def prompt_to_chat(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    return text\n",
    "\n",
    "def infer(model, prompt, l=100, use_chat = True, temperature=0.4, top_p = 0.8):\n",
    "    if use_chat:\n",
    "        prompt = prompt_to_chat(prompt)\n",
    "    model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=l,\n",
    "        temperature=temperature, \n",
    "        top_p=top_p,\n",
    "        do_sample=True ,  \n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "    return response\n",
    "\n",
    "\n",
    "prompts =  [\n",
    "    'Как в BlackBox можно вывести данные на консоль?', \n",
    "    'Какой тип данных в Component Pascal используется для хранения целых чисел?', \n",
    "    'МОДУЛЬ i21егэDemo2010C4ru;', \n",
    "    'Component Pascal is Oberon microsystems refinement of?', \n",
    "    'Log.String(', \n",
    "    'Типом целой константы является'\n",
    "]  # feel free to add a few more that are not 100% assiciated with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c5d4b9ec-9c96-4b55-b7d2-b4a1d8e1ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_diff(use_chat,l):\n",
    "    print(f\"USING CHAT TEMPLATE = {use_chat}\")\n",
    "        \n",
    "    baseline = [infer(reference_model, p, l = l, use_chat=use_chat) for p in prompts]\n",
    "    check = [infer(model, p, l = l, use_chat=use_chat) for p in prompts]\n",
    "    rows = []\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        # replace placeholders in the format() arguments\n",
    "        rows.append(row_template.format(prompt, baseline[i], check[i]))\n",
    "    display(HTML(table_template.format('\\n'.join(rows))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d62e1c1d-9778-4fe4-85dd-05053174412e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING CHAT TEMPLATE = True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border:1px solid black\" >\n",
       "  <tr>\n",
       "    <th style=\"text-align: center; border:1px solid black\">PROMPT</th>\n",
       "    <th style=\"text-align: center; border:1px solid black\">BEFORE</th>\n",
       "    <th style=\"text-align: center; border:1px solid black\">AFTER</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Как в BlackBox можно вывести данные на консоль?`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Вопрос о выводе данных на консоль в контексте программирования с использованием фреймворка BlackBox может быть связан с различными языковами программ</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Чтобы напечатать что-то на стандартный поток вывода (консоль), используйте процедуры WriteChar, WriteInt или другие аналогичные.</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Какой тип данных в Component Pascal используется для хранения целых чисел?`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">В Pascal, как и во многих других языках программирования, для хранения целых чисел обычно используется тип данных `integer`. Этот тип поддерживает различные операции ари</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">В языке программирования Component Pascal целые числа могут быть представлены как SHORTCHAR, CHAR или INTEGER. Символ 0X может использоваться для обозначения от</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`МОДУЛЬ i21егэDemo2010C4ru;`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Ваш вопрос содержит строку, которая выглядит как часть имени модуля или класса в программировании. Однако, если это была попытка задать конкретный вопрос</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Этот модуль предназначен для изучения примерами основных средств программирования в Блэкбоксе, а именно:\n",
       "\u000e\tпроцедуры-фабри</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Component Pascal is Oberon microsystems refinement of?`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">It seems you are asking about the relationship between Component Pascal and Oberon microsystems. To clarify, \"Component Pascal\" could refer to a specific product or software component developed by Oberon Microsystems</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Oberon microsystems developed the language Component Pascal as a refinement and extension of the existing language Oberon. It was also refined in several ways to make it more user-friendly, safe, and</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Log.String(`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">It seems like you're asking about the `String` method in a logging context, but your question is incomplete. The `String` method does not exist for strings in most programming languages; instead</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">ersion: 0.8 \n",
       "поставлена под модуль i21sysIn в целях разработки языка Оберон-3 (см.</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Типом целой константы является`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Вопрос о \"типом целой константы\" может быть немного неоднозначным, так как термин \"константа\" в контексте программирования обычно</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">типа значения. Константа означает значение, которое не может быть изменено в процессе выполнения программы.\n",
       "\n",
       "Дополнительно модуль i21sysIn содержит процеду</pre></td>\n",
       "  </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_diff(True, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2e557ba3-4ec0-40d7-9427-4728d44a4f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING CHAT TEMPLATE = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border:1px solid black\" >\n",
       "  <tr>\n",
       "    <th style=\"text-align: center; border:1px solid black\">PROMPT</th>\n",
       "    <th style=\"text-align: center; border:1px solid black\">BEFORE</th>\n",
       "    <th style=\"text-align: center; border:1px solid black\">AFTER</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Как в BlackBox можно вывести данные на консоль?`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> I'm trying to debug a Java application using the Eclipse IDE and want to see the output of the `System.out.println` statements in my code. How can I achieve this?\n",
       "\n",
       "In the documentation</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> В частности, как это сделать для массива целых?\n",
       "\n",
       "Во-первых, нужно открыть поток вывода (ввода) в рабочий. Это делается</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Какой тип данных в Component Pascal используется для хранения целых чисел?`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> В компоненте Pascal, для хранения целых чисел обычно используется тип `Int`. Этот тип представляет собой 32-битное беззнаковое целое число. Если</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> \n",
       "Для хранения целых чисел, таких как 123 или -456789, используются типы SHORTCHAR (длина 1 бай</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`МОДУЛЬ i21егэDemo2010C4ru;`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> // Простой модуль для демонстрации\n",
       "\n",
       "// Модуль должен быть подключен к системе\n",
       "#include \"i21egedemo2010c4ru</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> (* info21, 2010-10-07 *)\n",
       "\tIMPORT  Log := StdLog,  In := i21sysIn,  Texts := AD</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Component Pascal is Oberon microsystems refinement of?`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> \n",
       "Oberon is a high-level, multi-paradigm object-oriented programming language that was developed in the 1970s. It is known for its support for concurrency and distributed</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> or rather generalization of Component Information Systems (CIS) as proposed by the Object-Oriented Database Society. CIS provides a type and its metamodel, i.e., an abstract description of</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Log.String(`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">1024) 这个代码片段是用Go语言编写的，它试图将一个字符串截断为不超过1024字符的长度。在这个字符串被截断</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> \"Enter\" );  Log.Ln;\n",
       "\tEND Do;\n",
       "\n",
       "END ObxCount0.\n",
       "\n",
       "Листинг 5-2. Пример, показывающий работу команды Count\n",
       "\n",
       "   </pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Типом целой константы является`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> число π (пи), которое приближается к значению 3.14159... и не может быть точно выражено в виде дроби, так как это число</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> ее значение. Это типы INTEGER, LONGINT, SHORTCHAR, CHAR, BYTE, SHORTINT, INTEGER, LONG, SHORTREAL и REAL.\n",
       "\n",
       "CONST false, true\n",
       "Эти кон</pre></td>\n",
       "  </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_diff(False, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3c970689-2e87-4b49-bee9-55978ee178b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чтобы выполнить команду, нужно сначала открыть окошко лога (двойной клик по имени модуля Log; или Файлы -> Открыть документ... / File->Open Dialog, затем нажать Ctrl+O). После этого можно напечатать что-нибудь в обычном текстовом редакторе и нажать Ctrl+0.\n",
      "\n",
      "Если хотите, чтобы команда выполнялась после компиляции программы, то следует добавить её к меню Правка (Edit) через Инфо->Меню (Info->Menu Listers), либо напрямую открывать меню после компиляции:\n",
      "\u000e\t\t\"Compile &List Modules\"\t\"\"\t\"DevCompiler.ListModules\"\t\"TextCmds.SelectionGuard\"\n",
      "\u000eПосле компиляции программ:\n",
      "\u000e\t\"Compile &All\"\t\"\"\t\"DevCompiler.CompileThis\"\t\"\"\n",
      "\u000e\t\"Compile &Module List\"\t\"\"\t\"DevCompiler.CompileModuleList\"\t\"TextCmds.SelectionGuard\"\n",
      "\u000e\t\"Com&pile Module List &As Assistant\"\t\"\"\t\"DevCompiler.InitAndCompileModuleList\"\t\"Text\n"
     ]
    }
   ],
   "source": [
    "print(infer(model, 'Ты помошник по среде Component Pascal. Ответь на вопрос: Как мне вывести строку hello в окно лога?', 256, use_chat = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "828dbb24-08bc-4ed3-9d90-365a0a5b4144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 19:40:08,590 Resetting dropped connection: huggingface.co\n",
      "2025-01-22 19:40:09,095 https://huggingface.co:443 \"HEAD /MTSAIR/Cotype-Nano/resolve/main/config.json HTTP/11\" 200 0\n",
      "2025-01-22 19:40:29,916 https://huggingface.co:443 \"HEAD /MTSAIR/Cotype-Nano/resolve/main/generation_config.json HTTP/11\" 200 0\n"
     ]
    }
   ],
   "source": [
    "checkpoint = transformers.AutoModelForCausalLM.from_pretrained(\"./results/checkpoint-4500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "893ee176-9274-43dd-b577-db944a851289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для начала вам нужно открыть окно логи, если оно еще не открыто. Для этого нажмите Ctrl+O (или выберите File->Log). Затем выполните следующие шаги:\n",
      "\n",
      "1. Нажмите Ctrl+N для создания нового текстового документа.\n",
      "2. Вставьте в него строку \"hello\".\n",
      "3. Выделите эту строку и кликните правой кнопкой мыши по выделенной строке. В появившемся контекстном меню выберите \"Выполнить как\" -> \"Вывести в лог\". \n",
      "4. Если возникает ошибка, проверьте правильность написания слова \"hello\".\n",
      "\n",
      "Если все сделано правильно, то в окне лога появится сообщение об успешной печать строки hello.\n",
      "\n",
      "Надеюсь, что эта инструкция была понятна. Если у вас есть дополнительные вопросы или предложения, пожалуйста, сообщите об этом.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(infer(checkpoint, 'Ты помошник по среде Component Pascal. Ответь на вопрос: Как мне вывести строку hello в окно лога?', 256, use_chat = True, temperature = 0.1, top_p = 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee14080-d26e-4164-9080-a06910d3b6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
