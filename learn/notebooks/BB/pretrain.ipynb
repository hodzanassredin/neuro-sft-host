{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c552ef18-d476-4ac1-a932-fe39ae52e36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan 25 16:17:10 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.02              Driver Version: 566.03         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   41C    P8              5W /  165W |     611MiB /  16380MiB |     18%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e04ccb-e0e0-4c48-a9c8-efb88642a788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "import peft\n",
    "import datasets\n",
    "import evaluate\n",
    "import time\n",
    "assert torch.cuda.is_available(), \"you need cuda for this part\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6278fc09-ac11-4db4-9b35-f1191285d8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "055ff20d-43e1-4f7d-8722-441da81abb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/app/datasets/oberon/docs/bb_ru\"\n",
    "model_name = \"Qwen/Qwen2.5-Coder-3B-Instruct\"\n",
    "#model_name = 'MTSAIR/Cotype-Nano'\n",
    "\n",
    "EPOCHS = 7\n",
    "PACKED=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10faa754-675f-49fa-af89-9e2376c3b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_model_name = model_name.split(\"/\")[-1].replace(':', \"_\")\n",
    "dataset_name = dataset_path.split(\"/\")[-1]\n",
    "sft_model_path = f\"/app/models/{dataset_name}_{only_model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ee4c9c-0b68-4bd9-ad3a-b59b9bfad4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "peft_config = peft.LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        \"mlp.down_proj\",\n",
    "        \"self_attn.k_proj\",\n",
    "        \"self_attn.o_proj\",\n",
    "        \"mlp.up_proj\",\n",
    "        \"self_attn.v_proj\",\n",
    "        \"mlp.gate_proj\",\n",
    "        \"self_attn.q_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=peft.TaskType.CAUSAL_LM\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61beaedd-5d90-43a1-8b76-ffd9b9a8e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00042bcc-14f2-49c4-af7d-ae4a73113d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_texts():\n",
    "    file_names = [] \n",
    "    for subdir, dirs, files in os.walk(dataset_path):\n",
    "        if \"/Rsrc/\" in subdir:\n",
    "            continue\n",
    "        for file in files:\n",
    "            file_names.append(os.path.join(subdir, file))\n",
    "    texts = []\n",
    "    for f in file_names:\n",
    "        with open(f, 'r', encoding='utf-8') as file:\n",
    "            texts.append(file.read() + tokenizer.eos_token)\n",
    "    return file_names,texts\n",
    "names, texts = load_texts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61245f8b-57cf-4c3d-8f14-612dfd9d6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#names = [n[len(dataset_path)+1:] for n in names]\n",
    "#text_dataset = datasets.Dataset.from_dict({\"texts\":texts,\"names\" : names})\n",
    "\n",
    "#text_dataset.push_to_hub('hodza/BlackBox.Shkola.2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b02ab931-2403-411e-a760-99f39b7fa17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'overflow_to_sample_mapping', 'labels'],\n",
       "        num_rows: 5986\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'overflow_to_sample_mapping', 'labels'],\n",
       "        num_rows: 666\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 512  # Максимальная длина последовательности\n",
    "stride = 32      # Шаг перекрытия    \n",
    "def tokenize_with_stride(texts):\n",
    "    tokenized_data = tokenizer(\n",
    "        texts,\n",
    "        max_length=block_size,\n",
    "        truncation=True,\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        padding=\"max_length\",  # Дополняем до block_size\n",
    "        return_tensors=\"pt\",   # Возвращаем тензоры PyTorch\n",
    "        add_special_tokens = False,\n",
    "    )\n",
    "    tokenized_data[\"labels\"] = tokenized_data[\"input_ids\"]\n",
    "    return datasets.Dataset.from_dict(tokenized_data).train_test_split(test_size=0.1,shuffle=False)\n",
    "    \n",
    "lm_datasets = tokenize_with_stride(texts)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c32575a6-319b-4b12-8d09-d6b4f124e3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сборка Блэкбокса для школьных уроков информатики\n",
      "\n",
      "«Блэкбокс  практически идеальная среда для обучения программированию.»\n",
      "Т.Евсикова, научный сотрудник, \n",
      "Институт математики и информатики, Вильнюс, Литва\n",
      "\n",
      "«... школьная сборка  это блестящая работа, лучше я еще не видел. \n",
      "Для меня главное, что показан путь, каким надо двигаться в рамках моих учебных дел. \n",
      "Это очень ценно и для развивающихся учителей: они сами будут достраивать <сборку> \n",
      "в нужном направлении. Никаких специальных институтов не нужно.»\n",
      "В.В.Лаптев, профессор, \n",
      "Астраханский гос. тех. университет\n",
      "\n",
      "«... скачал вашу сборку и как в сказку попал ... \n",
      "Ввод через любое выделение в документе, дружелюбная гипернавигация, \n",
      "<ключевые> слова <можно писать> на русском, мастер нового приложения с подсказками ...»\n",
      "Александр Шостак, студент,\n",
      "специальность \"экономическая информатика\"\n",
      "\n",
      "Основа школьной сборки  уникальная современная бесплатная и открытая среда программирования Блэкбокс (BlackBox Component Builder), воплотившая полувековой (считая с Алгола-60) опыт разработки технологий и методов программирования (школа Никлауса Вирта в цюрихском университете ETH, исследовательская лаборатория Xerox Palo Alto Research Center и др.).\n",
      "\n",
      "Система Блэкбокс реализует в широко доступном виде идеи проекта Оберон легендарного Никлауса Вирта и его соратника Юрга Гуткнехта (см. книгу «Проект Оберон», ДМК Пресс, 2012), а также предшественников (системы Lilith/ETHZ и Mesa/Xerox PARC).\n",
      "\u000eЯзык программирования, используемый в Блэкбок\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(lm_datasets[\"train\"][3][\"input_ids\"], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06627dbd-c8f8-4b09-942d-58439e3cfcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 22.56s/it]\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelForCausalLM.from_pretrained(model_name, device_map=device,quantization_config=bnb_config,)\n",
    "model._hf_peft_config_loaded = True  # silence a warning from HF trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e45a2f70-9a12-4316-a57b-7815bb33e07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 29,933,568 || all params: 3,115,872,256 || trainable%: 0.9607\n"
     ]
    }
   ],
   "source": [
    "model = peft.get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93b6e086-af49-4f73-b5dd-c15772e989a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b852f7f4-46a7-4f41-9e5e-3e8eabacb6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 16:20:52,081 Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-01-25 16:20:52,725 https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/metrics/evaluate-metric/bleu/evaluate-metric/bleu.py HTTP/11\" 404 0\n",
      "2025-01-25 16:20:52,731 Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-01-25 16:20:53,078 https://huggingface.co:443 \"HEAD /spaces/evaluate-metric/bleu/resolve/v0.4.3/bleu.py HTTP/11\" 404 0\n",
      "2025-01-25 16:20:53,082 Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-01-25 16:20:53,438 https://huggingface.co:443 \"HEAD /spaces/evaluate-metric/bleu/resolve/main/bleu.py HTTP/11\" 200 0\n",
      "2025-01-25 16:20:53,461 Starting new HTTPS connection (1): github.com:443\n",
      "2025-01-25 16:20:53,856 https://github.com:443 \"HEAD /tensorflow/nmt/raw/master/nmt/scripts/bleu.py HTTP/11\" 302 0\n",
      "2025-01-25 16:20:53,857 Starting new HTTPS connection (1): raw.githubusercontent.com:443\n",
      "2025-01-25 16:20:54,159 https://raw.githubusercontent.com:443 \"HEAD /tensorflow/nmt/master/nmt/scripts/bleu.py HTTP/11\" 200 0\n",
      "2025-01-25 16:20:54,177 Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-01-25 16:20:54,500 https://huggingface.co:443 \"HEAD /spaces/evaluate-metric/bleu/resolve/main/tokenizer_13a.py HTTP/11\" 200 0\n",
      "2025-01-25 16:20:54,535 Attempting to acquire lock 139615758432112 on /hf/modules/evaluate_modules/metrics/evaluate-metric--bleu.lock\n",
      "2025-01-25 16:20:54,542 Lock 139615758432112 acquired on /hf/modules/evaluate_modules/metrics/evaluate-metric--bleu.lock\n",
      "2025-01-25 16:20:54,553 Attempting to release lock 139615758432112 on /hf/modules/evaluate_modules/metrics/evaluate-metric--bleu.lock\n",
      "2025-01-25 16:20:54,554 Lock 139615758432112 released on /hf/modules/evaluate_modules/metrics/evaluate-metric--bleu.lock\n"
     ]
    }
   ],
   "source": [
    "metric = evaluate.load(\"bleu\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efa722e4-6baa-4cdd-913e-23afa5159987",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "data_collator = transformers.DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=f\"./results/{dataset_name}_{only_model_name}/{timestr}/\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    bf16=torch.cuda.get_device_capability(torch.cuda.current_device())[0] >= 8,  \n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    #save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=32,\n",
    "    warmup_steps=100, \n",
    "    #eval_steps=32, \n",
    "    #max_steps=512,\n",
    "    \n",
    "    #load_best_model_at_end=True,\n",
    ")\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    #compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d30406-4ef7-458d-af63-69a5e6576979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='5236' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3/5236 00:04 < 6:25:58, 0.23 it/s, Epoch 0.00/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "#trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "44e3bbe0-ea00-44d9-b532-48a5862bf6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='513' max='513' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [513/513 01:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 5.12\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcf1c380-ca65-47f0-8ba2-86ca5b777572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 14:16:24,142 Resetting dropped connection: huggingface.co\n",
      "2025-01-23 14:16:24,795 https://huggingface.co:443 \"HEAD /MTSAIR/Cotype-Nano/resolve/main/config.json HTTP/11\" 200 0\n",
      "2025-01-23 14:16:24,982 https://huggingface.co:443 \"HEAD /MTSAIR/Cotype-Nano/resolve/main/config.json HTTP/11\" 200 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/app/models/bb_ru_Cotype-Nano_20250123-100550/tokenizer_config.json',\n",
       " '/app/models/bb_ru_Cotype-Nano_20250123-100550/special_tokens_map.json',\n",
       " '/app/models/bb_ru_Cotype-Nano_20250123-100550/vocab.json',\n",
       " '/app/models/bb_ru_Cotype-Nano_20250123-100550/merges.txt',\n",
       " '/app/models/bb_ru_Cotype-Nano_20250123-100550/added_tokens.json',\n",
       " '/app/models/bb_ru_Cotype-Nano_20250123-100550/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_path = sft_model_path + f\"_{timestr}\"\n",
    "model.save_pretrained(final_path)\n",
    "tokenizer.save_pretrained(final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6b8fd17-3cfa-4b8b-8277-083b69c57850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/models/bb_ru_Cotype-Nano_20250123-100550'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d8aa123-881c-4af1-bf8a-f44fd6631057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 20:38:24,715 Resetting dropped connection: huggingface.co\n",
      "2025-01-25 20:38:25,242 https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-Coder-3B-Instruct/resolve/main/config.json HTTP/11\" 200 0\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 22.93s/it]\n",
      "2025-01-25 20:39:11,632 https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-Coder-3B-Instruct/resolve/main/generation_config.json HTTP/11\" 200 0\n"
     ]
    }
   ],
   "source": [
    "reference_model = transformers.AutoModelForCausalLM.from_pretrained(model_name, device_map=device,quantization_config=bnb_config,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0226c3f9-1c41-4010-b00b-0fa0e125839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "table_template = \"\"\"<table style=\"border:1px solid black\" >\n",
    "  <tr>\n",
    "    <th style=\"text-align: center; border:1px solid black\">PROMPT</th>\n",
    "    <th style=\"text-align: center; border:1px solid black\">BEFORE</th>\n",
    "    <th style=\"text-align: center; border:1px solid black\">AFTER</th>\n",
    "  </tr>\n",
    "{}\n",
    "</table>\"\"\"\n",
    "\n",
    "row_template = '''  <tr>\n",
    "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`{}`</pre></td>\n",
    "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
    "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
    "  </tr>'''\n",
    "\n",
    "def prompt_to_chat(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    return text\n",
    "\n",
    "def infer(model, prompt, l=100, use_chat = True, temperature=0.4, top_p = 0.8):\n",
    "    if use_chat:\n",
    "        prompt = prompt_to_chat(prompt)\n",
    "    model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=l,\n",
    "        temperature=temperature, \n",
    "        top_p=top_p,\n",
    "        do_sample=True ,  \n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "    return response\n",
    "\n",
    "\n",
    "prompts =  [\n",
    "    'Как в BlackBox можно вывести данные на консоль?', \n",
    "    'Какой тип данных в Component Pascal используется для хранения целых чисел?', \n",
    "    'МОДУЛЬ i21егэDemo2010C4ru;', \n",
    "    'Component Pascal is Oberon microsystems refinement of?', \n",
    "    'Log.String(', \n",
    "    'Типом целой константы является'\n",
    "]  # feel free to add a few more that are not 100% assiciated with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5d4b9ec-9c96-4b55-b7d2-b4a1d8e1ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_diff(use_chat,l):\n",
    "    print(f\"USING CHAT TEMPLATE = {use_chat}\")\n",
    "        \n",
    "    baseline = [infer(reference_model, p, l = l, use_chat=use_chat) for p in prompts]\n",
    "    check = [infer(model, p, l = l, use_chat=use_chat) for p in prompts]\n",
    "    rows = []\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        # replace placeholders in the format() arguments\n",
    "        rows.append(row_template.format(prompt, baseline[i], check[i]))\n",
    "    display(HTML(table_template.format('\\n'.join(rows))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d62e1c1d-9778-4fe4-85dd-05053174412e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING CHAT TEMPLATE = True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border:1px solid black\" >\n",
       "  <tr>\n",
       "    <th style=\"text-align: center; border:1px solid black\">PROMPT</th>\n",
       "    <th style=\"text-align: center; border:1px solid black\">BEFORE</th>\n",
       "    <th style=\"text-align: center; border:1px solid black\">AFTER</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Как в BlackBox можно вывести данные на консоль?`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">В BlackBox (также известном как Prometheus) вы можете выводить данные на консоль с помощью различных методов. Вот несколько распространенных способов:\n",
       "\n",
       "1. **Исп</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">В BlackBox, чтобы вывести данные на консоль, достаточно вызвать процедуру StdLog.WriteString или StdLog.Ln. Например:\n",
       "\n",
       "MODULE i21примВывод</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Какой тип данных в Component Pascal используется для хранения целых чисел?`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">В Component Pascal используется тип данных `Integer` для хранения целых чисел.<|im_end|></pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">В Component Pascal целые числа представлены типами INTEGER и SHORTINT. Тип INTEGER может хранить значения от -2147483648 до 2</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`МОДУЛЬ i21егэDemo2010C4ru;`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> It looks like you've provided a module name in a specific format: `i21егэDemo2010C4ru`. This appears to be a custom naming convention or identifier</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Модуль переведен на русский язык, но не проверялся на ошибки. В частности, не проверялась работа с файлами.\n",
       "Возможно, нужна</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Component Pascal is Oberon microsystems refinement of?`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Component Pascal is a programming language developed by Oberon Microsystems. It is a subset of the Oberon programming language and is used for developing software components. Component Pascal is designed to be more efficient and</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Component Pascal is a variant of the Oberon programming language that was developed by the Oberon microsystems company. It was designed to be a more efficient and flexible implementation of the Oberon language,</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Log.String(`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> It looks like you're trying to use the `Log.String` method, which is part of a logging framework. However, I don't have enough context to provide a specific implementation or explanation.</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">It looks like you're trying to use a command or function in a way that isn't supported by the Log module. The Log module is part of the BlackBox Component Builder's standard library and</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Типом целой константы является`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Типом целой константы в большинстве языков программирования является \"целое число\". Это может быть 8-, 16-, 32- или</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Типом целой константы является INTEGER или LONGINT в зависимости от размера числа.\n",
       "\n",
       "Примеры:\n",
       "1234567890\n",
       "-12</pre></td>\n",
       "  </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_diff(True, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e557ba3-4ec0-40d7-9427-4728d44a4f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING CHAT TEMPLATE = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border:1px solid black\" >\n",
       "  <tr>\n",
       "    <th style=\"text-align: center; border:1px solid black\">PROMPT</th>\n",
       "    <th style=\"text-align: center; border:1px solid black\">BEFORE</th>\n",
       "    <th style=\"text-align: center; border:1px solid black\">AFTER</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Как в BlackBox можно вывести данные на консоль?`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">\n",
       "\n",
       "В BlackBox можно вывести данные на консоль с помощью различных методов. Вот несколько распространенных способов:\n",
       "\n",
       "1. **Использование `print` функции:</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> Как сделать, чтобы текст был выведен в окно, а не в консоль?\n",
       "\u000eВ BlackBox есть два модуля для работы с текстом: TextModels и TextViews</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Какой тип данных в Component Pascal используется для хранения целых чисел?`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> \n",
       "\n",
       "В Component Pascal тип данных для хранения целых чисел обычно называется:\n",
       "\n",
       "A) Integer\n",
       "B) Real\n",
       "C) String\n",
       "D) Boolean\n",
       "\n",
       "Правильный ответ:</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> (Числа с плавающей точкой тоже могут быть целыми, например, 1.0, 2.5, 3.14159</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`МОДУЛЬ i21егэDemo2010C4ru;`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> 1. Экспорт модуля: export module i21egegDemo2010C4ru; 2. Импорт модуля: import i</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> (* 2010-09-28, Ф.В.Ткачев *)\n",
       "\tПОДКЛЮЧИТЬ Вывод := i21</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Component Pascal is Oberon microsystems refinement of?`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">?\n",
       "A) C\n",
       "B) Java\n",
       "C) Pascal\n",
       "D) C++\n",
       "Answer:\n",
       "A) C\n",
       "\n",
       "Oberon microsystems was a company that developed a programming language called Oberon</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> A. Smalltalk B. Modula-2 C. Component Pascal D. C++ E. Java F. Visual Basic G. Python H. Ruby I. Perl J. Lisp K.</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Log.String(`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">“error”, err.Error())\n",
       "\t\treturn\n",
       "\t}\n",
       "\tdefer func() {\n",
       "\t\tif err := recover(); err != nil {\n",
       "\t\t\tlog.Error().Interface(“error”, err).Msgf(</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> \"  \" ); Log.Int( v.len );\n",
       "\t\t\tLog.Ln\n",
       "\t\tEND;\n",
       "\t\tLog.Ln; Log.String(\"End of list\"); Log.Ln\n",
       "\tEND Do;\n",
       "\n",
       "</pre></td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Типом целой константы является`</pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">:\n",
       "\n",
       "1. 0\n",
       "2. 1\n",
       "3. -1\n",
       "4. 1000\n",
       "\n",
       "Правильный ответ: 1, 2, 3, </pre></td>\n",
       "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> целое число, которое может быть представлено в диапазоне от MIN(INTEGER) до MAX(INTEGER). В зависимости от контекста целая константа может быть интер</pre></td>\n",
       "  </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_diff(False, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c970689-2e87-4b49-bee9-55978ee178b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чтобы вывести строку \"hello\" в окно лога, выполните следующий код:\n",
      "\n",
      "\tStdLog.String(\"hello\"); StdLog.Ln\n",
      "\n",
      "Этот код экспортируется модулем StdLog, который должен быть импортирован в начале программы. Команда String используется для вывода текста в лог. Команда Ln используется для перехода на новую строку в логе. Команды могут быть вызваны из любого места программы.\n",
      "\n",
      "Если вы хотите, чтобы строка была выведена сразу после запуска программы, то можно использовать команду:\n",
      "\n",
      "\tStdLog.Open;  StdLog.String(\"hello\");  StdLog.Ln;\n",
      "\n",
      "В этом случае программа открывает лог, а затем выводит строку \"hello\" и переходит на новую строку. Если вы хотите, чтобы программа не открывала лог, то достаточно убрать команду Open.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(infer(model, 'Ты помошник по среде Component Pascal. Ответь на вопрос: Как мне вывести строку hello в окно лога?', 256, use_chat = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "828dbb24-08bc-4ed3-9d90-365a0a5b4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = transformers.AutoModelForCausalLM.from_pretrained(\"./results/20250122-220441/checkpoint-1220/\", device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "893ee176-9274-43dd-b577-db944a851289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для целых чисел обычно используют тип INTEGER. Однако, если значения могут быть только некоторым предопределенным количеством значений, следует использовать тип SHORTINT, чтобы избежать возможных потерь точности, которые могут возникнуть при делении на 2. В некоторых случаях лучше использовать LONGINT.\n",
      "\n",
      "Все последующие примеры использует LONGINT в качестве основного типа. Если результаты вычислений становятся непредсказуемыми, если используется другой тип.\n",
      "\n",
      "Пример:\n",
      "\t\n",
      "\tPROCEDURE Ddouble* (a, b: LONGINT);\n",
      "\tBEGIN\n",
      "\t\tDIAGNOSTIC;\n",
      "\t\tStdLog.Nl;\n",
      "\t\tStdLog.String(\"Ddouble \"); StdLog.Int(a + b, 0); StdLog.Ln;\n",
      "\t\tStdLog.String(DefaCT(a + b)); StdLog.Ln\n",
      "\tEND Ddouble;\n",
      "\n",
      "В этом примере использовано значение эффекта (defacto) стандартного модуля Math, который включает в себя итоговое значение.\n",
      "\u000eПосле применения команд DIAGNOSTIC (см. ниже), он будет выровнен по левому краю, а не\n"
     ]
    }
   ],
   "source": [
    "print(infer(checkpoint, 'Какой тип использовать для хранения целых чисел?', 256, use_chat = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee14080-d26e-4164-9080-a06910d3b6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
