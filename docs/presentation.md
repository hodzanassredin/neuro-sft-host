---
marp: true
theme: default
paginate: true
---

# Обучение нейросети с помощью SFT и RLHF

## Автор: Антон Шелин

---

## Введение

Экзаменационная работа по курсу "Построй свой ChatGPT".

---

## Цель

Обучить нейросеть Copilot для небольшой системы программирования BlackBox и языка Component Pascal.

---

## Проблема

Существующие модели путают Component Pascal с другими языками, такими как Delphi и Pascal, а также ничего не знают про систему BlackBox.

---

## Набор датасетов

1. Написан crawler для сбора данных с форума, посвященного этому ЯП и системе.
2. Экспортирован чат из Telegram.
3. Взята вся документация и код из системы, сконвертированы в txt формат.
4. На основе документации и кода с помощью модели Qwen-coder2.5 сгенерирован набор пар вопрос-ответ.

---

## Базовая модель

1. Приоритет на маленькие модели 1.5B или 3B, максимум 7B.
2. Байзлайн модель Cotype Nano(хорошие результаты в бенчмарках, но неустойчива к изменению настроек)
3. Хочется попробовать Qwen Coder 2.5 

---

## Обучение Документаця и код

Обучение на файлах документации и кода. 
Токенезация: перекрывающиеся куски длиной 512 токенов и перекрытие 32 токена

Проблема: переобучение.
Решение: увеличение дропаута и снижение скорости обучения, раннее прерывание.

После правок, модель стала давать осмысленные и корректные ответы.

---

## Обучение QA

Обучение на вопросах ответах было проведено с помощью чат темплейтов.

Результаты ухудьшились:
1. Переобучение
2. Неверные обобщения в сгенерированных вопросах и ответах

Изменения:

1. Генерировать пары с указанием ширины контекста(модуль, весь фреймворк, яп)
2. Генерировать пары только на более общей документации.
3. уменьшить скорость обучения
   
---
## Инфраструктура

1. ллм хостинг vllm
2. фронтенд web assembly bootstrap
3. бекенд web sockets asp.net core
4. хранение чатов PG + pgvector для RAG
5. телеграм бот [@blackbox_cp_helper_bot](https://t.me/blackbox_cp_helper_bot)
6. добавлены метрики TTFT...
---

## Проблема выделения кода
Модель не выделяет куски кода с помощью markdown. В обучающем корпусе все является текстом и код и описание, нет выделения.
Решения:
1. Промпт инженеринг. Добавлен системный промпт с попыткой заставить модель генерить правильный ответ. Иногда работает. :-(
2. В датасете с форума есть выделения кода. Можно попытаться дообучить модель. 
3. Использовать LLM для разметки кода в датасете.
4. Обучить BERT модель для классификации слов/токенов на датасете форума. Обработать весь датасет.
5. Все тексты из файлов кода перед токенизацией оборачивать в маркдаун.


---

## Проблема квантизации
Если обучить lora используя bnb квантизованную модель, то далее невозможно сделать merge с оригинальной моделью не повлияв на качество. 
Решение:
Пока не обнаружил как корректно смерджить. Необходимо узнать как это корректно хостить.

---

### Планы
1. Квантизовать модель и выложить на Ollama. 
2. Добавить в BlackBox возможность работать с моделью через ollama или openai ендпоинт.

---
## Заключение

С помощью SFT была получена модель, которая понимает новый домен и генерирует осмысленные ответы по языку Component Pascal и системе BlackBox. Также была создана инфраструктура для использования модели.

---

## Вопросы и ответы

Спасибо за внимание!

---